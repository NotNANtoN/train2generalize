{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9886e22-166b-4ad4-ac6d-a44e27eedf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc5dc7f4-7621-4ad7-9987-886b449ceb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = \"CIFAR10\" # ImageNet, MNIST, FashionMNIST, CIFAR10\n",
    "\n",
    "\n",
    "# load data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_data, val_data, test_data = None, None, None\n",
    "if dataset == \"ImageNet\":\n",
    "    num_classes = 1000\n",
    "    resolution = 224\n",
    "    n_channels = 3\n",
    "    transform = transforms.Compose([transforms.Resize(resolution), transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "    dev_data = datasets.ImageNet(root=\"data\", split=\"train\", download=True, transform=transform)\n",
    "    val_data = datasets.ImageNet(root=\"data\", split=\"val\", download=True, transform=transform)\n",
    "    test_data = datasets.ImageNet(root=\"data\", split=\"val\", download=True, transform=transform)\n",
    "\n",
    "elif dataset == \"MNIST\" or dataset == \"FashionMNIST\":\n",
    "    num_classes = 10\n",
    "    resolution = 28\n",
    "    n_channels = 1\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                                    ])\n",
    "    if dataset == \"MNIST\":\n",
    "        dev_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "        test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "    else:\n",
    "        dev_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "        test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "elif dataset == \"CIFAR10\":\n",
    "    num_classes = 10\n",
    "    resolution = 32\n",
    "    n_channels = 3\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                    ])\n",
    "    dev_data = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "    test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97d6e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define conv net\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes, n_channels, resolution):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(n_channels, 32, 3, 1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        self.dropout1 = torch.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(resolution**2 // 4 * 64, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, num_classes)        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = torch.nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e368663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from numpy import pad\n",
    "\n",
    "\n",
    "test_in = torch.rand(1, n_channels, resolution, resolution)\n",
    "conv1 = torch.nn.Conv2d(n_channels, 32, 3, 1, padding=1)\n",
    "out = conv1(test_in)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77857d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if val_data is None:\n",
    "    # split dev data into train and validation\n",
    "    train_size = int(0.8 * len(dev_data))\n",
    "    val_size = len(dev_data) - train_size\n",
    "    train_data, val_data = torch.utils.data.random_split(dev_data, [train_size, val_size])\n",
    "\n",
    "# split train data into train and generalization\n",
    "gen_size = int(0.8 * len(train_data))\n",
    "train_size = len(train_data) - gen_size\n",
    "train_data, gen_data = torch.utils.data.random_split(train_data, [train_size, gen_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e93b644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolution * resolution * 64 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b712c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3020, -2.2326, -2.2576, -2.2867, -2.3919, -2.2940, -2.3469, -2.3093,\n",
      "         -2.2751, -2.3395]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[1]])\n"
     ]
    }
   ],
   "source": [
    "# test conv net\n",
    "model = ConvNet(num_classes, n_channels, resolution)\n",
    "input_data = torch.randn(1, n_channels, resolution, resolution)\n",
    "output = model(input_data)\n",
    "print(output)\n",
    "pred = output.argmax(dim=1, keepdim=True)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95b4cb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.3047, Accuracy: 929/10000 (9.29%)\n",
      "Train Epoch: 1 [0/1600 (0%)]\tLoss: 2.307580\n",
      "Average loss: 2.0316, Accuracy: 2759/10000 (27.59%)\n",
      "Train Epoch: 2 [0/1600 (0%)]\tLoss: 2.075940\n",
      "Average loss: 1.9057, Accuracy: 3170/10000 (31.70%)\n",
      "Train Epoch: 3 [0/1600 (0%)]\tLoss: 1.952086\n",
      "Average loss: 1.7962, Accuracy: 3741/10000 (37.41%)\n",
      "Train Epoch: 4 [0/1600 (0%)]\tLoss: 1.705595\n",
      "Average loss: 1.6801, Accuracy: 4078/10000 (40.78%)\n",
      "Train Epoch: 5 [0/1600 (0%)]\tLoss: 1.595343\n",
      "Average loss: 1.6405, Accuracy: 4220/10000 (42.20%)\n",
      "Train Epoch: 6 [0/1600 (0%)]\tLoss: 1.579450\n",
      "Average loss: 1.5809, Accuracy: 4265/10000 (42.65%)\n",
      "Train Epoch: 7 [0/1600 (0%)]\tLoss: 1.415821\n",
      "Average loss: 1.5497, Accuracy: 4443/10000 (44.43%)\n",
      "Train Epoch: 8 [0/1600 (0%)]\tLoss: 1.060264\n",
      "Average loss: 1.5564, Accuracy: 4462/10000 (44.62%)\n",
      "Train Epoch: 9 [0/1600 (0%)]\tLoss: 1.276158\n",
      "Average loss: 1.5265, Accuracy: 4544/10000 (45.44%)\n",
      "Train Epoch: 10 [0/1600 (0%)]\tLoss: 1.000759\n",
      "Average loss: 1.5357, Accuracy: 4593/10000 (45.93%)\n"
     ]
    }
   ],
   "source": [
    "# train loss function\n",
    "def train_loss(model, data, target):\n",
    "    output = model(data)\n",
    "    loss = torch.nn.functional.nll_loss(output, target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "# define train2generalize loss function\n",
    "def train2generalize(model, data, target, gen_loader, optimizer, reset_net=False):\n",
    "    # train for one step, then test on one generalization data batch and backprop\n",
    "\n",
    "    # save current model parameters\n",
    "    if reset_net:\n",
    "        model_params = copy.deepcopy(model.state_dict())        \n",
    "\n",
    "    # update weights\n",
    "    loss = train_loss(model, data, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(create_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    # test on one generalization data batch\n",
    "    gen_data, gen_target = next(iter(gen_loader))\n",
    "    gen_data, gen_target = gen_data.to(device), gen_target.to(device)\n",
    "    gen_loss = train_loss(model, gen_data, gen_target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if reset_net:\n",
    "        # reset model parameters to only make use of second order information\n",
    "        # restore model parameters by subtracting the difference between the current and saved parameters\n",
    "        for param, saved_param in zip(model.parameters(), model_params.values()):\n",
    "            param.data -= param.data - saved_param.detach()\n",
    "\n",
    "    return gen_loss\n",
    "\n",
    "\n",
    "def train2generalize2(model, data, target, gen_loader, optimizer, fast_net, inner_lr=0.001, **kwargs):\n",
    "    #print(data.device, target.device, model.fc1.weight.device)\n",
    "    loss_fast = train_loss(model, data, target)\n",
    "    grad = torch.autograd.grad(loss_fast, model.parameters(), create_graph=True)\n",
    "    fast_weights = list(map(lambda p: p[1] - inner_lr * p[0], zip(grad, model.parameters())))\n",
    "\n",
    "    # load fast weights into fast_net\n",
    "    fast_net.load_state_dict(dict(zip(fast_net.state_dict().keys(), fast_weights)))\n",
    "    # print grad of fast_net to check if it is the same as grad\n",
    "    print(\"grad\", grad[0][0,0,0,0])\n",
    "    print(\"fast_net\", fast_net.conv1.weight.grad[0,0,0,0])\n",
    "    gen_data, gen_target = next(iter(gen_loader))\n",
    "    gen_data, gen_target = gen_data.to(device), gen_target.to(device)\n",
    "\n",
    "    loss_gen = train_loss(fast_net, gen_data, gen_target)\n",
    "    return loss_gen\n",
    "\n",
    "\n",
    "def train2generalize_with_l2l(model, data, target, gen_loader, optimizer, fast_net, inner_lr=0.001, **kwargs):\n",
    "    import learn2learn as l2l\n",
    "    maml = l2l.algorithms.MAML(model, lr=inner_lr)\n",
    "    for iteration in range(1):\n",
    "        optimizer.zero_grad()\n",
    "        task_model = maml.clone()  # torch.clone() for nn.Modules\n",
    "        adaptation_loss = train_loss(task_model, data, target)\n",
    "        task_model.adapt(adaptation_loss)  # computes gradient, update task_model in-place\n",
    "\n",
    "        gen_data, gen_target = next(iter(gen_loader))\n",
    "        gen_data, gen_target = gen_data.to(device), gen_target.to(device)\n",
    "        evaluation_loss = train_loss(task_model, gen_data, gen_target)\n",
    "        #evaluation_loss.backward()  # gradients w.r.t. maml.parameters()\n",
    "        #optimizer.step()\n",
    "    return evaluation_loss\n",
    "   \n",
    "\n",
    "def train2generalize_with_higher(model, data, target, gen_loader, optimizer, fast_net, inner_lr=0.001, **kwargs):\n",
    "    import higher\n",
    "    # When you want to branch from the current state of your model and unroll\n",
    "    # optimization, follow this example. This context manager gets a snapshot of the\n",
    "    # current version of the model and optimizer at the point where you want to\n",
    "    # start unrolling and create a functional version `fmodel` which executes the\n",
    "    # forward pass of `model` with implicit fast weights which can be read by doing\n",
    "    # `fmodel.parameters()`, and a differentiable optimizer `diffopt` which ensures\n",
    "    # that at each step, gradient of `fmodel.parameters()` with regard to initial\n",
    "    # fast weights `fmodel.parameters(time=0)` (or any other part of the unrolled\n",
    "    # model history) is defined.\n",
    "    n_inner_iter = 1\n",
    "    inner_opt = torch.optim.SGD(model.parameters(), lr=inner_lr)\n",
    "\n",
    "    with higher.innerloop_ctx(model, inner_opt, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "        for _ in range(n_inner_iter):\n",
    "            logits = fmodel(data)  # modified `params` can also be passed as a kwarg\n",
    "            loss = torch.nn.functional.nll_loss(logits, target)\n",
    "            # no need to call loss.backwards()\n",
    "            diffopt.step(loss)  # note that `step` must take `loss` as an argument!\n",
    "        # The final set of adapted parameters will induce some\n",
    "        # final loss and accuracy on the query dataset.\n",
    "        # These will be used to update the model's meta-parameters.\n",
    "\n",
    "\n",
    "        # At this point, or at any point in the iteration, you can take the\n",
    "        # gradient of `fmodel.parameters()` (or equivalently\n",
    "        # `fmodel.fast_params`) w.r.t. `fmodel.parameters(time=0)` (equivalently\n",
    "        # `fmodel.init_fast_params`). i.e. `fast_params` will always have\n",
    "        # `grad_fn` as an attribute, and be part of the gradient tape.\n",
    "\n",
    "        # At the end of your inner loop you can obtain these e.g. ...\n",
    "        #grad_of_grads = torch.autograd.grad(\n",
    "        #    meta_loss_fn(fmodel.parameters()), fmodel.parameters(time=0))\n",
    "        gen_data, gen_target = next(iter(gen_loader))\n",
    "        gen_data, gen_target = gen_data.to(device), gen_target.to(device)\n",
    "        eval_loss = train_loss(fmodel, gen_data, gen_target)\n",
    "    return eval_loss\n",
    "\n",
    "\n",
    "\n",
    "# define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, use_train2generalize=False, gen_loader=None, train_to_generalize_kwargs=None, \n",
    "         save_graph=False):\n",
    "    model.train()\n",
    "\n",
    "    if use_train2generalize:\n",
    "        fast_net = copy.deepcopy(model).to(device)\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if use_train2generalize:\n",
    "            if train_to_generalize_kwargs[\"use_l2l\"]:\n",
    "                loss = train2generalize_with_l2l(model, data, target, gen_loader, optimizer, fast_net, **train_to_generalize_kwargs)\n",
    "            elif train_to_generalize_kwargs[\"use_higher\"]:\n",
    "                loss = train2generalize_with_higher(model, data, target, gen_loader, optimizer, fast_net, **train_to_generalize_kwargs)\n",
    "            else:\n",
    "                loss = train2generalize2(model, data, target, gen_loader, optimizer, fast_net, **train_to_generalize_kwargs)\n",
    "        else:\n",
    "            loss = train_loss(model, data, target)\n",
    "\n",
    "        if batch_idx == 0 and save_graph:\n",
    "            # visualize comp graph\n",
    "            from torchviz import make_dot\n",
    "            make_dot(loss).render(\"comp_graph\", format=\"png\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# define test function\n",
    "@torch.inference_mode()\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += torch.nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.2f}%)')\n",
    "\n",
    "# define hyperparameters\n",
    "use_train2generalize = True\n",
    "epochs = 10\n",
    "train_to_generalize_kwargs = {'reset_net': 1,\n",
    "                              'inner_lr': 0.001,\n",
    "                              'use_l2l': 0,\n",
    "                              'use_higher': 1,\n",
    "                              }\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "# define train and test data loaders\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "gen_loader = DataLoader(gen_data, batch_size=batch_size, shuffle=True)\n",
    "# create loader that combine train and generalization data\n",
    "train_gen_loader = DataLoader(ConcatDataset([train_data, gen_data]), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# define model\n",
    "model = ConvNet(num_classes, n_channels, resolution).to(device)\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    " \n",
    "# train model\n",
    "used_train_loader = train_loader if use_train2generalize else train_gen_loader\n",
    "\n",
    "test(model, device, val_loader)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    save_graph = epoch == 1\n",
    "    train(model, device, train_loader, optimizer, epoch, use_train2generalize=use_train2generalize, gen_loader=gen_loader, train_to_generalize_kwargs=train_to_generalize_kwargs, save_graph=save_graph)\n",
    "    test(model, device, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55713b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.5119, Accuracy: 4650/10000 (46.50%)\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1009e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.4001, Accuracy: 4931/10000 (49.31%)\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e482955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.4332, Accuracy: 4908/10000 (49.08%)\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6873ed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.5352, Accuracy: 4574/10000 (45.74%)\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b0777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
